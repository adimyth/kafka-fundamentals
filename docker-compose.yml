version: "3.8"

services:
    broker:
        image: confluentinc/cp-kafka:7.5.0
        container_name: broker
        hostname: broker
        ports:
            - 9092:9092
        environment:
            KAFKA_PROCESS_ROLES: "broker,controller"
            KAFKA_NODE_ID: 1
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            # Listeners that the broker will advertise to producers and clients
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
            # JMX (Java Management Extensions) is used to expose a wide range of metrics related to topics, brokers, producers, consumers, and more. This information can be invaluable for monitoring the health and performance of a Kafka cluster.
            KAFKA_JMX_PORT: 9999
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:29093
            KAFKA_LISTENERS: PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://localhost:9092
            CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"

    schema-registry:
        image: confluentinc/cp-schema-registry:7.5.0
        container_name: schema-registry
        ports:
            - "8081:8081"
        depends_on:
            - broker
        environment:
            SCHEMA_REGISTRY_HOST_NAME: schema-registry
            SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:29092

    kafka-connect:
        image: confluentinc/cp-kafka-connect-base:7.5.0
        container_name: kafka-connect
        depends_on:
            - broker
            - schema-registry
        ports:
            - 8083:8083
        environment:
            CONNECT_BOOTSTRAP_SERVERS: "broker:29092"
            CONNECT_REST_PORT: 8083
            CONNECT_GROUP_ID: kafka-connect
            CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
            CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
            CONNECT_STATUS_STORAGE_TOPIC: _connect-status
            CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
            CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
            CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
            CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
            CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/data/connect-jars
            CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
            CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
        volumes:
            - $PWD/data:/data
        command:
            - bash
            - -c
            - |
                echo "Installing Connector"
                confluent-hub install --no-prompt debezium/debezium-connector-postgresql:2.2.1
                confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:14.0.10
                #
                echo "Launching Kafka Connect worker"
                /etc/confluent/docker/run &
                #
                sleep infinity

    ksqldb:
        image: confluentinc/ksqldb-server:0.29.0
        container_name: ksqldb
        depends_on:
            - broker
            - schema-registry
        ports:
            - "8088:8088"
        environment:
            KSQL_LISTENERS: http://0.0.0.0:8088
            KSQL_BOOTSTRAP_SERVERS: broker:29092
            KSQL_KSQL_SERVICE_ID: confluent_ksql_01
            KSQL_PRODUCER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
            KSQL_CONSUMER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
            KSQL_KSQL_CONNECT_URL: http://kafka-connect:8083
            KSQL_KSQL_HIDDEN_TOPICS: "^_.*"
        volumes:
            - ./wait-for-it.sh:/wait-for-it.sh
        command:
            [
                "/wait-for-it.sh",
                "broker:29092",
                "--",
                "/wait-for-it.sh",
                "schema-registry:8081",
                "--",
                "/etc/confluent/docker/run",
            ]

    control-center:
        image: confluentinc/cp-enterprise-control-center:7.5.0
        container_name: control-center
        depends_on:
            - broker
            - schema-registry
        ports:
            - "9021:9021"
        environment:
            CONTROL_CENTER_BOOTSTRAP_SERVERS: "broker:29092"
            CONTROL_CENTER_CONNECT_CONNECT_CLUSTER: "kafka-connect:8083"
            CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
            CONTROL_CENTER_KSQL_KSQLDB_URL: "http://ksqldb:8088"
            CONTROL_CENTER_KSQL_KSQLDB_ADVERTISED_URL: "http://localhost:8088"
            # Useful settings for development/laptop use - modify as needed for Prod
            CONFLUENT_METRICS_TOPIC_REPLICATION: 1
            CONTROL_CENTER_REPLICATION_FACTOR: 1
            CONTROL_CENTER_COMMAND_TOPIC_REPLICATION: 1
            CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_REPLICATION: 1
            CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
            CONTROL_CENTER_INTERNAL_TOPICS_REPLICATION: 1
            CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
            CONTROL_CENTER_STREAMS_NUM_STREAM_THREADS: 1
            CONTROL_CENTER_STREAMS_CACHE_MAX_BYTES_BUFFERING: 104857600
        volumes:
            - ./wait-for-it.sh:/wait-for-it.sh
        command:
            [
                "/wait-for-it.sh",
                "broker:29092",
                "--",
                "/wait-for-it.sh",
                "schema-registry:8081",
                "--",
                "/wait-for-it.sh",
                "connect:8083",
                "--",
                "/wait-for-it.sh",
                "ksqldb-server:8088",
                "--",
                "/etc/confluent/docker/run",
            ]

    postgres:
        image: debezium/postgres:15
        container_name: postgres
        ports:
            - 5432:5432
        environment:
            - POSTGRES_PASSWORD=somesupersecretpassword
            - POSTGRES_USER=postgresuser
            - POSTGRES_DB=kafka-demo
        volumes:
            - ./init-wal-level.sh:/docker-entrypoint-initdb.d/init-wal-level.sh
            - ./data:/data

    elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
        container_name: elasticsearch
        hostname: elasticsearch
        ports:
            - 9200:9200
        environment:
            xpack.security.enabled: "false"
            ES_JAVA_OPTS: "-Xms1g -Xmx1g"
            discovery.type: "single-node"
            cluster.name: "postgresql-debezium-kafka-elasticsearch-demo"
            node.name: "elasticsearch-node-01"

    kibana:
        image: docker.elastic.co/kibana/kibana:8.10.2
        container_name: kibana
        hostname: kibana
        depends_on:
            - elasticsearch
        ports:
            - 5601:5601
        environment:
            xpack.security.enabled: "false"
            discovery.type: "single-node"
        command:
            - bash
            - -c
            - |
                /usr/local/bin/kibana-docker &
                echo "Waiting for Kibana to be ready ⏳"
                while [ $$(curl -H 'kbn-xsrf: true' -s -o /dev/null -w %{http_code} http://localhost:5601/api/saved_objects/_find?type=index-pattern&search_fields=title&search=*) -ne 200 ] ; do 
                  echo -e "\t" $$(date) " Kibana saved objects request response: " $$(curl -H 'kbn-xsrf: true' -o /dev/null -w %{http_code} -s http://localhost:5601/api/saved_objects/_find?type=index-pattern&search_fields=title&search=*) $$(curl -H 'kbn-xsrf: true' -s http://localhost:5601/api/saved_objects/_find?type=index-pattern&search_fields=title&search=*) " (waiting for 200)"
                  sleep 5  
                done

                echo -e "\t" $$(date) " Kibana saved objects request response: " $$(curl -H 'kbn-xsrf: true' -o /dev/null -w %{http_code} -s http://localhost:5601/api/saved_objects/_find?type=index-pattern&search_fields=title&search=*) $$(curl -H 'kbn-xsrf: true' -s http://localhost:5601/api/saved_objects/_find?type=index-pattern&search_fields=title&search=*)

                echo -e "\n--\n+> Pre-creating index pattern"
                curl -s -XPOST 'http://localhost:5601/api/saved_objects/index-pattern/postgresql-debezium.orders' \
                  -H 'kbn-xsrf: nevergonnagiveyouup' \
                  -H 'Content-Type: application/json' \
                  -d '{"attributes":{"title":"postgresql-debezium.orders","timeFieldName":"CREATE_TS"}}'

                echo -e "\n--\n+> Setting the index pattern as default"
                curl -s -XPOST 'http://localhost:5601/api/kibana/settings' \
                  -H 'kbn-xsrf: nevergonnagiveyouup' \
                  -H 'content-type: application/json' \
                  -d '{"changes":{"defaultIndex":"postgresql-debezium.orders"}}'

                echo -e "\n--\n+> Opt out of Kibana telemetry"
                curl 'http://localhost:5601/api/telemetry/v2/optIn' \
                    -H 'kbn-xsrf: nevergonnagiveyouup' \
                    -H 'content-type: application/json' \
                    -H 'accept: application/json' \
                    --data-binary '{"enabled":false}' \
                    --compressed

                sleep infinity

    kcat:
        image: edenhill/kcat:1.7.1
        container_name: kcat
        entrypoint:
            - /bin/sh
            - -c
            - |
                apk add jq; 
                while [ 1 -eq 1 ];do sleep 60;done
